{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varsigma</th>\n",
       "      <th>kappa</th>\n",
       "      <th>delta</th>\n",
       "      <th>v0</th>\n",
       "      <th>rho</th>\n",
       "      <th>tau</th>\n",
       "      <th>stockPrice</th>\n",
       "      <th>strike</th>\n",
       "      <th>moneyness</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.16</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.00</td>\n",
       "      <td>150</td>\n",
       "      <td>1.20</td>\n",
       "      <td>45.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.16</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.00</td>\n",
       "      <td>160</td>\n",
       "      <td>1.12</td>\n",
       "      <td>39.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.16</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.00</td>\n",
       "      <td>170</td>\n",
       "      <td>1.06</td>\n",
       "      <td>32.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.16</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.00</td>\n",
       "      <td>180</td>\n",
       "      <td>1.00</td>\n",
       "      <td>27.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.16</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.00</td>\n",
       "      <td>190</td>\n",
       "      <td>0.95</td>\n",
       "      <td>22.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748995</th>\n",
       "      <td>0.34</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.41</td>\n",
       "      <td>200</td>\n",
       "      <td>0.86</td>\n",
       "      <td>25.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748996</th>\n",
       "      <td>0.34</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.41</td>\n",
       "      <td>210</td>\n",
       "      <td>0.82</td>\n",
       "      <td>22.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748997</th>\n",
       "      <td>0.34</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.41</td>\n",
       "      <td>220</td>\n",
       "      <td>0.78</td>\n",
       "      <td>19.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748998</th>\n",
       "      <td>0.34</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.41</td>\n",
       "      <td>230</td>\n",
       "      <td>0.75</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748999</th>\n",
       "      <td>0.34</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.41</td>\n",
       "      <td>250</td>\n",
       "      <td>0.69</td>\n",
       "      <td>12.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1749000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         varsigma  kappa  delta    v0   rho  tau  stockPrice  strike  \\\n",
       "0            0.16   1.78   0.61  0.06 -0.62  1.0      180.00     150   \n",
       "1            0.16   1.78   0.61  0.06 -0.62  1.0      180.00     160   \n",
       "2            0.16   1.78   0.61  0.06 -0.62  1.0      180.00     170   \n",
       "3            0.16   1.78   0.61  0.06 -0.62  1.0      180.00     180   \n",
       "4            0.16   1.78   0.61  0.06 -0.62  1.0      180.00     190   \n",
       "...           ...    ...    ...   ...   ...  ...         ...     ...   \n",
       "1748995      0.34   2.23   0.55  0.14 -0.83  1.0      171.41     200   \n",
       "1748996      0.34   2.23   0.55  0.14 -0.83  1.0      171.41     210   \n",
       "1748997      0.34   2.23   0.55  0.14 -0.83  1.0      171.41     220   \n",
       "1748998      0.34   2.23   0.55  0.14 -0.83  1.0      171.41     230   \n",
       "1748999      0.34   2.23   0.55  0.14 -0.83  1.0      171.41     250   \n",
       "\n",
       "         moneyness  price  \n",
       "0             1.20  45.78  \n",
       "1             1.12  39.00  \n",
       "2             1.06  32.78  \n",
       "3             1.00  27.17  \n",
       "4             0.95  22.18  \n",
       "...            ...    ...  \n",
       "1748995       0.86  25.49  \n",
       "1748996       0.82  22.21  \n",
       "1748997       0.78  19.28  \n",
       "1748998       0.75  16.67  \n",
       "1748999       0.69  12.33  \n",
       "\n",
       "[1749000 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"csv_files/train.csv\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varsigma</th>\n",
       "      <th>kappa</th>\n",
       "      <th>delta</th>\n",
       "      <th>v0</th>\n",
       "      <th>rho</th>\n",
       "      <th>tau</th>\n",
       "      <th>stockPrice</th>\n",
       "      <th>strike</th>\n",
       "      <th>moneyness</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.749000e+06</td>\n",
       "      <td>1.749000e+06</td>\n",
       "      <td>1.749000e+06</td>\n",
       "      <td>1.749000e+06</td>\n",
       "      <td>1.749000e+06</td>\n",
       "      <td>1.749000e+06</td>\n",
       "      <td>1.749000e+06</td>\n",
       "      <td>1.749000e+06</td>\n",
       "      <td>1.749000e+06</td>\n",
       "      <td>1.749000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.770000e-01</td>\n",
       "      <td>1.710900e+00</td>\n",
       "      <td>3.634333e-01</td>\n",
       "      <td>9.103333e-02</td>\n",
       "      <td>-5.388667e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.795318e+02</td>\n",
       "      <td>1.960000e+02</td>\n",
       "      <td>9.384750e-01</td>\n",
       "      <td>2.772866e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.372941e-01</td>\n",
       "      <td>7.905263e-01</td>\n",
       "      <td>2.244740e-01</td>\n",
       "      <td>3.526943e-02</td>\n",
       "      <td>2.017475e-01</td>\n",
       "      <td>4.316752e-01</td>\n",
       "      <td>1.251597e+01</td>\n",
       "      <td>3.039738e+01</td>\n",
       "      <td>1.608779e-01</td>\n",
       "      <td>1.714504e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>-9.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.500100e+02</td>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>6.000000e-01</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.600000e-01</td>\n",
       "      <td>1.097500e+00</td>\n",
       "      <td>1.700000e-01</td>\n",
       "      <td>6.000000e-02</td>\n",
       "      <td>-7.100000e-01</td>\n",
       "      <td>6.900000e-01</td>\n",
       "      <td>1.704700e+02</td>\n",
       "      <td>1.700000e+02</td>\n",
       "      <td>8.100000e-01</td>\n",
       "      <td>1.399000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.800000e-01</td>\n",
       "      <td>1.765000e+00</td>\n",
       "      <td>3.400000e-01</td>\n",
       "      <td>9.000000e-02</td>\n",
       "      <td>-5.400000e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.796900e+02</td>\n",
       "      <td>1.950000e+02</td>\n",
       "      <td>9.200000e-01</td>\n",
       "      <td>2.619000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>2.392500e+00</td>\n",
       "      <td>5.525000e-01</td>\n",
       "      <td>1.200000e-01</td>\n",
       "      <td>-3.700000e-01</td>\n",
       "      <td>1.310000e+00</td>\n",
       "      <td>1.885400e+02</td>\n",
       "      <td>2.200000e+02</td>\n",
       "      <td>1.060000e+00</td>\n",
       "      <td>3.973000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>7.900000e-01</td>\n",
       "      <td>1.500000e-01</td>\n",
       "      <td>-2.000000e-01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.099700e+02</td>\n",
       "      <td>2.500000e+02</td>\n",
       "      <td>1.400000e+00</td>\n",
       "      <td>1.006500e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           varsigma         kappa         delta            v0           rho  \\\n",
       "count  1.749000e+06  1.749000e+06  1.749000e+06  1.749000e+06  1.749000e+06   \n",
       "mean   2.770000e-01  1.710900e+00  3.634333e-01  9.103333e-02 -5.388667e-01   \n",
       "std    1.372941e-01  7.905263e-01  2.244740e-01  3.526943e-02  2.017475e-01   \n",
       "min    1.000000e-02  3.000000e-02  1.000000e-02  3.000000e-02 -9.000000e-01   \n",
       "25%    1.600000e-01  1.097500e+00  1.700000e-01  6.000000e-02 -7.100000e-01   \n",
       "50%    2.800000e-01  1.765000e+00  3.400000e-01  9.000000e-02 -5.400000e-01   \n",
       "75%    4.000000e-01  2.392500e+00  5.525000e-01  1.200000e-01 -3.700000e-01   \n",
       "max    5.000000e-01  3.000000e+00  7.900000e-01  1.500000e-01 -2.000000e-01   \n",
       "\n",
       "                tau    stockPrice        strike     moneyness         price  \n",
       "count  1.749000e+06  1.749000e+06  1.749000e+06  1.749000e+06  1.749000e+06  \n",
       "mean   1.000000e+00  1.795318e+02  1.960000e+02  9.384750e-01  2.772866e+01  \n",
       "std    4.316752e-01  1.251597e+01  3.039738e+01  1.608779e-01  1.714504e+01  \n",
       "min    0.000000e+00  1.500100e+02  1.500000e+02  6.000000e-01 -0.000000e+00  \n",
       "25%    6.900000e-01  1.704700e+02  1.700000e+02  8.100000e-01  1.399000e+01  \n",
       "50%    1.000000e+00  1.796900e+02  1.950000e+02  9.200000e-01  2.619000e+01  \n",
       "75%    1.310000e+00  1.885400e+02  2.200000e+02  1.060000e+00  3.973000e+01  \n",
       "max    2.000000e+00  2.099700e+02  2.500000e+02  1.400000e+00  1.006500e+02  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain features and label -> X, Y\n",
    "X, Y = train_data.drop([\"moneyness\", \"price\"], axis=1), train_data[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data -> X_normalized, Y_normalized\n",
    "## Normalize the model parameters in a domain\n",
    "def custom_min_max_normalization(x, xmin, xmax):\n",
    "    return (2 * x - (xmax + xmin)) / (xmax - xmin)\n",
    "\n",
    "model_parameters = X.drop([\"tau\", \"stockPrice\", \"strike\"], axis=1)\n",
    "option_properties = X.drop([\"varsigma\", \"kappa\", \"delta\", \"v0\", \"rho\"], axis=1)\n",
    "\n",
    "min_vals = pd.Series({ \n",
    "    'varsigma': 0.01,\n",
    "    'kappa': 0,\n",
    "    'v0': 0.03,\n",
    "    'delta': 0.01,\n",
    "    'rho': -0.9\n",
    "})\n",
    "\n",
    "max_vals = pd.Series({\n",
    "    'varsigma': 0.5,\n",
    "    'kappa': 3.0,\n",
    "    'v0': 0.15,\n",
    "    'delta': 0.8,\n",
    "    'rho': -0.2\n",
    "})\n",
    "\n",
    "normalized_model_parameters = pd.DataFrame()\n",
    "for column in model_parameters.columns:\n",
    "    normalized_model_parameters[column] = custom_min_max_normalization(\n",
    "        model_parameters[column], \n",
    "        min_vals[column], \n",
    "        max_vals[column]\n",
    "    )\n",
    "\n",
    "scaler = MinMaxScaler() \n",
    "normalized_option_properties = scaler.fit_transform(option_properties)\n",
    "normalized_option_properties = pd.DataFrame(normalized_option_properties, columns=option_properties.columns)\n",
    "\n",
    "X_normalized = pd.concat([normalized_model_parameters, normalized_option_properties], axis=1).values\n",
    "\n",
    "Y_normalized = scaler.fit_transform(Y.values.reshape(-1, 1))\n",
    "Y_normalized = pd.Series(Y_normalized.flatten(), name=Y.name).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"csv_files/outOfSample.csv\")\n",
    "test = round(test,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varsigma</th>\n",
       "      <th>kappa</th>\n",
       "      <th>delta</th>\n",
       "      <th>v0</th>\n",
       "      <th>rho</th>\n",
       "      <th>tau</th>\n",
       "      <th>stockPrice</th>\n",
       "      <th>strike</th>\n",
       "      <th>moneyness</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42400.000000</td>\n",
       "      <td>42400.00000</td>\n",
       "      <td>42400.000000</td>\n",
       "      <td>42400.00000</td>\n",
       "      <td>42400.000000</td>\n",
       "      <td>42400.000000</td>\n",
       "      <td>42400.000000</td>\n",
       "      <td>42400.000000</td>\n",
       "      <td>42400.000000</td>\n",
       "      <td>42400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.300600</td>\n",
       "      <td>1.72840</td>\n",
       "      <td>0.346600</td>\n",
       "      <td>0.09240</td>\n",
       "      <td>-0.525600</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>176.103230</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>0.939944</td>\n",
       "      <td>30.159162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.130192</td>\n",
       "      <td>0.76819</td>\n",
       "      <td>0.225335</td>\n",
       "      <td>0.03592</td>\n",
       "      <td>0.194786</td>\n",
       "      <td>0.422904</td>\n",
       "      <td>10.120805</td>\n",
       "      <td>22.360943</td>\n",
       "      <td>0.124657</td>\n",
       "      <td>15.160794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.03000</td>\n",
       "      <td>-0.870000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>155.110000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.210000</td>\n",
       "      <td>1.23000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.06000</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>168.540000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>18.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.305000</td>\n",
       "      <td>1.80000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.09000</td>\n",
       "      <td>-0.520000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>175.160000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>29.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.28000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>1.395000</td>\n",
       "      <td>183.490000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>40.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.490000</td>\n",
       "      <td>2.99000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.15000</td>\n",
       "      <td>-0.210000</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>199.870000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           varsigma        kappa         delta           v0           rho  \\\n",
       "count  42400.000000  42400.00000  42400.000000  42400.00000  42400.000000   \n",
       "mean       0.300600      1.72840      0.346600      0.09240     -0.525600   \n",
       "std        0.130192      0.76819      0.225335      0.03592      0.194786   \n",
       "min        0.040000      0.10000      0.010000      0.03000     -0.870000   \n",
       "25%        0.210000      1.23000      0.150000      0.06000     -0.700000   \n",
       "50%        0.305000      1.80000      0.310000      0.09000     -0.520000   \n",
       "75%        0.420000      2.28000      0.520000      0.12000     -0.350000   \n",
       "max        0.490000      2.99000      0.780000      0.15000     -0.210000   \n",
       "\n",
       "                tau    stockPrice        strike     moneyness         price  \n",
       "count  42400.000000  42400.000000  42400.000000  42400.000000  42400.000000  \n",
       "mean       1.100000    176.103230    190.000000      0.939944     30.159162  \n",
       "std        0.422904     10.120805     22.360943      0.124657     15.160794  \n",
       "min        0.250000    155.110000    160.000000      0.700000      0.010000  \n",
       "25%        0.805000    168.540000    175.000000      0.840000     18.660000  \n",
       "50%        1.100000    175.160000    190.000000      0.930000     29.560000  \n",
       "75%        1.395000    183.490000    205.000000      1.040000     40.860000  \n",
       "max        1.950000    199.870000    220.000000      1.250000     81.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestX, TestY = test.drop([\"moneyness\",\"price\"], axis=1), test[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize TestX\n",
    "test_model_parameters = TestX.drop([\"tau\", \"stockPrice\", \"strike\"], axis=1)\n",
    "test_option_properties = TestX.drop([\"varsigma\", \"kappa\", \"delta\", \"v0\", \"rho\"], axis=1)\n",
    "\n",
    "normalized_test_model_parameters = pd.DataFrame()\n",
    "for column in test_model_parameters.columns:\n",
    "    normalized_test_model_parameters[column] = custom_min_max_normalization(\n",
    "        test_model_parameters[column], \n",
    "        min_vals[column], \n",
    "        max_vals[column]\n",
    "    )\n",
    "\n",
    "# Fit the scaler with option_properties from the training data\n",
    "scaler_option_properties = MinMaxScaler() \n",
    "scaler_option_properties.fit(option_properties)\n",
    "\n",
    "# Transform the option_properties from the test data\n",
    "normalized_test_option_properties = scaler_option_properties.transform(test_option_properties)\n",
    "normalized_test_option_properties = pd.DataFrame(normalized_test_option_properties, columns=test_option_properties.columns)\n",
    "\n",
    "TestX_normalized = pd.concat([normalized_test_model_parameters, normalized_test_option_properties], axis=1).values\n",
    "\n",
    "# Now the scaler for Y\n",
    "scaler_Y = MinMaxScaler()\n",
    "scaler_Y.fit(Y.values.reshape(-1, 1))\n",
    "\n",
    "# Normalize TestY\n",
    "TestY_normalized = scaler_Y.transform(TestY.values.reshape(-1, 1))  # Use transform, not fit_transform\n",
    "TestY_normalized = pd.Series(TestY_normalized.flatten(), name=TestY.name).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best FNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 layers, nodes = 64, epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m576\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,121</span> (51.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,121\u001b[0m (51.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,121</span> (51.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,121\u001b[0m (51.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3ms/step - loss: 3.7172e-04 - val_loss: 1.2695e-05 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3ms/step - loss: 6.8915e-06 - val_loss: 6.6112e-06 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 3ms/step - loss: 4.6300e-06 - val_loss: 6.7760e-06 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 3ms/step - loss: 3.5974e-06 - val_loss: 7.5682e-06 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 3ms/step - loss: 3.0764e-06 - val_loss: 3.6437e-06 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 3ms/step - loss: 2.7527e-06 - val_loss: 3.6566e-06 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 3ms/step - loss: 2.4704e-06 - val_loss: 5.2879e-06 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 3ms/step - loss: 2.3344e-06 - val_loss: 4.3612e-06 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 3ms/step - loss: 2.1492e-06 - val_loss: 4.1646e-06 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 3ms/step - loss: 2.0630e-06 - val_loss: 2.9817e-06 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 3ms/step - loss: 1.9710e-06 - val_loss: 3.3745e-06 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 3ms/step - loss: 1.9004e-06 - val_loss: 4.0315e-06 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 3ms/step - loss: 1.8112e-06 - val_loss: 4.7594e-06 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 3ms/step - loss: 1.8082e-06 - val_loss: 3.6629e-06 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 3ms/step - loss: 1.7589e-06 - val_loss: 3.2115e-06 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 3ms/step - loss: 1.6757e-06 - val_loss: 2.2148e-06 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 3ms/step - loss: 1.6057e-06 - val_loss: 2.8314e-06 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 3ms/step - loss: 1.5743e-06 - val_loss: 3.3058e-06 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 3ms/step - loss: 1.5221e-06 - val_loss: 6.1342e-06 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 3ms/step - loss: 1.5012e-06 - val_loss: 2.2884e-06 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 3ms/step - loss: 9.2264e-07 - val_loss: 2.9600e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 3ms/step - loss: 9.2206e-07 - val_loss: 2.0787e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 3ms/step - loss: 9.1669e-07 - val_loss: 2.2885e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 3ms/step - loss: 9.0883e-07 - val_loss: 2.3013e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 3ms/step - loss: 8.9297e-07 - val_loss: 2.3838e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 3ms/step - loss: 8.8518e-07 - val_loss: 3.1693e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 3ms/step - loss: 8.8368e-07 - val_loss: 2.0938e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 3ms/step - loss: 8.8404e-07 - val_loss: 2.2465e-06 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 3ms/step - loss: 8.7532e-07 - val_loss: 2.2957e-06 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Data preprossesing -> X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "# Train - 80%, Test - 10%, Validation - 10%\n",
    "num_samples = len(X)\n",
    "train_size = int(0.8 * num_samples)\n",
    "valid_size = int(0.1 * num_samples)\n",
    "test_size = int(0.1 * num_samples)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X_train = X_normalized[:train_size]\n",
    "Y_train = Y_normalized[:train_size]\n",
    "\n",
    "X_val = X_normalized[train_size:train_size + valid_size]\n",
    "Y_val = Y_normalized[train_size:train_size + valid_size]\n",
    "\n",
    "X_test = X_normalized[train_size + valid_size:]\n",
    "Y_test = Y_normalized[train_size + valid_size:]\n",
    "\n",
    "def FNN():\n",
    "    FNN = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(64, input_shape=(X_train.shape[1],), activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(1, activation=tf.nn.relu)  \n",
    "    ])\n",
    "    return FNN\n",
    "\n",
    "# Create the model\n",
    "FNN = FNN()\n",
    "\n",
    "# Compile the model\n",
    "FNN.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Define early stopping with more patience\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7)\n",
    "\n",
    "# Define learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch != 0 and epoch % 20 == 0: \n",
    "        return lr * 0.5\n",
    "    else:\n",
    "        return lr\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Display the model summary\n",
    "FNN.summary()\n",
    "\n",
    "# Train the model\n",
    "history = FNN.fit(X_train, Y_train,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    epochs=50, batch_size=32, verbose=True, callbacks=[early_stopping, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 7.5968e-06\n",
      "Evaluate:  1.3526403563446365e-05\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step\n",
      "MSE desnormalized 0.13703729922274255\n",
      "\u001b[1m1325/1325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.9255e-06\n",
      "Test Evaluate:  2.6767766030388884e-06\n",
      "\u001b[1m1325/1325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "MSE desnormalized 0.02711685130968437\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate: \", FNN.evaluate(X_test, Y_test))\n",
    "pred = FNN.predict(X_test)\n",
    "pred_denormalized = scaler_Y.inverse_transform(pred)\n",
    "Y_test_denormalized = scaler_Y.inverse_transform(Y_test.reshape(-1, 1))\n",
    "mse = mean_squared_error(Y_test_denormalized, pred_denormalized)\n",
    "print(\"MSE desnormalized\", mse)\n",
    "\n",
    "print(\"Test Evaluate: \", FNN.evaluate(TestX_normalized, TestY_normalized))\n",
    "Testpred = FNN.predict(TestX_normalized)\n",
    "Testpred_denormalized = scaler_Y.inverse_transform(Testpred)\n",
    "TestY_denormalized = scaler_Y.inverse_transform(TestY_normalized.reshape(-1, 1))\n",
    "\n",
    "mse = mean_squared_error(TestY_denormalized, Testpred_denormalized)\n",
    "print(\"MSE desnormalized\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNN.save('BestFNN.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNN = load_model('BestFNN.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprossesing -> X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "# Train - 80%, Test - 10%, Validation - 10%\n",
    "num_samples = len(X)\n",
    "train_size = int(0.8 * num_samples)\n",
    "valid_size = int(0.1 * num_samples)\n",
    "test_size = int(0.1 * num_samples)\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X_train = X_normalized[:train_size]\n",
    "Y_train = Y_normalized[:train_size]\n",
    "\n",
    "X_val = X_normalized[train_size:train_size + valid_size]\n",
    "Y_val = Y_normalized[train_size:train_size + valid_size]\n",
    "\n",
    "X_test = X_normalized[train_size + valid_size:]\n",
    "Y_test = Y_normalized[train_size + valid_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43725/43725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 176us/step\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177us/step\n",
      "\u001b[1m5466/5466\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174us/step\n"
     ]
    }
   ],
   "source": [
    "train_predict = FNN.predict(X_train)\n",
    "val_predict = FNN.predict(X_val)\n",
    "test_predict = FNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 6.95677902653285e-07\n",
      "Mean Absolute Error (MAE): 0.0006641953915547844\n",
      "RMSE:  0.0008340730799236269\n",
      "R2:  0.9999753227010855\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(train_predict, Y_train)\n",
    "mae = mean_absolute_error(train_predict, Y_train)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_train, train_predict)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"R2: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 2.295870122066858e-06\n",
      "Mean Absolute Error (MAE): 0.0010878103722998746\n",
      "RMSE:  0.001515212896614485\n",
      "R2:  0.9999063103233223\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(val_predict, Y_val)\n",
    "mae = mean_absolute_error(val_predict, Y_val)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_val, val_predict)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"R2: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 1.3527303440817743e-05\n",
      "Mean Absolute Error (MAE): 0.0013949110354950177\n",
      "RMSE:  0.003677948265108924\n",
      "R2:  0.9994572053221485\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mse = mean_squared_error(test_predict, Y_test)\n",
    "mae = mean_absolute_error(test_predict, Y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_test, test_predict)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"R2: \", r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize TestX\n",
    "test_model_parameters = TestX.drop([\"tau\", \"stockPrice\", \"strike\"], axis=1)\n",
    "test_option_properties = TestX.drop([\"varsigma\", \"kappa\", \"delta\", \"v0\", \"rho\"], axis=1)\n",
    "\n",
    "normalized_test_model_parameters = pd.DataFrame()\n",
    "for column in test_model_parameters.columns:\n",
    "    normalized_test_model_parameters[column] = custom_min_max_normalization(\n",
    "        test_model_parameters[column], \n",
    "        min_vals[column], \n",
    "        max_vals[column]\n",
    "    )\n",
    "\n",
    "# Fit the scaler with option_properties from the training data\n",
    "scaler_option_properties = MinMaxScaler() \n",
    "scaler_option_properties.fit(option_properties)\n",
    "\n",
    "# Transform the option_properties from the test data\n",
    "normalized_test_option_properties = scaler_option_properties.transform(test_option_properties)\n",
    "normalized_test_option_properties = pd.DataFrame(normalized_test_option_properties, columns=test_option_properties.columns)\n",
    "\n",
    "TestX_normalized = pd.concat([normalized_test_model_parameters, normalized_test_option_properties], axis=1).values\n",
    "\n",
    "# Now the scaler for Y\n",
    "scaler_Y = MinMaxScaler()\n",
    "scaler_Y.fit(Y.values.reshape(-1, 1))\n",
    "\n",
    "# Normalize TestY\n",
    "TestY_normalized = scaler_Y.transform(TestY.values.reshape(-1, 1))  # Use transform, not fit_transform\n",
    "TestY_normalized = pd.Series(TestY_normalized.flatten(), name=TestY.name).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1325/1325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175us/step\n",
      "\u001b[1m1325/1325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173us/step\n",
      "\u001b[1m1325/1325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173us/step\n",
      "\u001b[1m1325/1325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176us/step\n",
      "\u001b[1m1325/1325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174us/step\n",
      "\u001b[1m1325/1325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191us/step\n",
      "\u001b[1m1325/1325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222us/step\n",
      "\u001b[1m1325/1325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186us/step\n",
      "\u001b[1m1325/1325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244us/step\n",
      "\u001b[1m1325/1325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186us/step\n",
      "Average execution time over 10 runs: 0.370668 seconds\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 10\n",
    "\n",
    "# List to store elapsed times\n",
    "elapsed_times = []\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    # Start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Code to measure\n",
    "    testpredict = FNN.predict(TestX_normalized)\n",
    "\n",
    "    # End time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Append elapsed time to list\n",
    "    elapsed_times.append(elapsed_time)\n",
    "\n",
    "# Calculate average elapsed time\n",
    "average_elapsed_time = np.mean(elapsed_times)\n",
    "\n",
    "print(f\"Average execution time over {num_iterations} runs: {average_elapsed_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1325/1325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176us/step\n"
     ]
    }
   ],
   "source": [
    "testpredict = FNN.predict(TestX_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 2.6767739715498964e-06\n",
      "Mean Absolute Error (MAE): 0.0010227094964302176\n",
      "RMSE:  0.0016360849524245055\n",
      "R2:  0.9998820207634256\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(testpredict, TestY_normalized)\n",
    "mae = mean_absolute_error(testpredict, TestY_normalized)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(TestY_normalized, testpredict)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"R2: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE denormalized: 0.02711685098258651\n",
      "MAE denormalized: 0.1029357152124445\n",
      "RMSE denormalized: 0.16467194959247464\n",
      "R2 denormalized (same as normalized): 0.9998820207634256\n"
     ]
    }
   ],
   "source": [
    "testpredict_denormalized = scaler_Y.inverse_transform(testpredict.reshape(-1, 1))\n",
    "TestY_denormalized = scaler_Y.inverse_transform(TestY_normalized.reshape(-1, 1))\n",
    "\n",
    "mse_denormalized = mean_squared_error(TestY_denormalized, testpredict_denormalized)\n",
    "mae_denormalized = mean_absolute_error(TestY_denormalized, testpredict_denormalized)\n",
    "rmse_denormalized = np.sqrt(mse_denormalized)\n",
    "\n",
    "print(\"MSE denormalized:\", mse_denormalized)\n",
    "print(\"MAE denormalized:\", mae_denormalized)\n",
    "print(\"RMSE denormalized:\", rmse_denormalized)\n",
    "print(\"R2 denormalized (same as normalized):\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
